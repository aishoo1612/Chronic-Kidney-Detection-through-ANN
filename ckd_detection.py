# -*- coding: utf-8 -*-
"""CKD_DETECTION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ec6VNxQYcD76IW1eqzqgwO99Mq5z454Z
"""

!pip install sklearn

!pip install matplotlib

#importing libraries
import glob 
from keras.models import Sequential, load_model
import numpy as np
import pandas as pd
from keras.layers import Dense
from sklearn.model_selection import train_test_split

from sklearn.preprocessing import LabelEncoder, MinMaxScaler
import keras as k
import matplotlib as plt

#Load the data 
from google.colab import files

uploaded = files.upload()

df = pd.read_csv('kidney_disease.csv')
#printfirst 5 ros
df.head()

#get the shape of the data (get the no. of rows and columns )
df.shape

#Create a list of column names to keep 
column_to_retain = ['sg','al','sc','hemo','pcv','wbcc','rbcc','htn','classification']
#here we drop the columns that are not in column_to_retain
df = df.drop([col for col in df.columns if not col in column_to_retain ], axis=1)

#drop the rows that are incomplete 
df = df.dropna(axis = 0)

#Transform the non-numeric datain the columns
for column in df.columns :
  if df[column].dtype == np.number:
    continue
  df[column] = LabelEncoder().fit_transform(df[column])

#Print the first 5 rows of the new clean df
# 0 for ckd
df.head()

#split the data into independent (x) and dependent (y) data set 
#independent data set contains features everything except for the target 
#Dependent Y creates the target

x= df.drop(['classification'], axis = 1)

y = df['classification']

#feature Scaling 
#MinMmaxScaler Method which scales the data set so that all the input feattures lie between 0 and 1
x_scaler = MinMaxScaler()
x_scaler.fit(x)
column_names = x.columns
x[column_names] = x_scaler.transform(x)

#Split the data into 80% training and 20% as testing and shuffle
x_train, x_test, y_train,y_test = train_test_split(x,y, test_size = 0.2, shuffle =True)

#build the model 
model = Sequential()
model.add( Dense(256, input_dim = len(x.columns) , kernel_initializer= k.initializers.random_normal(seed =13), activation='relu'))
model.add(Dense(1, activation='hard_sigmoid'))

#Comipling the model 
model.compile(loss='binary_crossentropy', optimizer='adam', metrics =['accuracy'])

#Train the model 
history = model.fit(x_train, y_train, epochs=2000, batch_size= x_train.shape[0])

#Save the model
model.save('ckd.model')

#Visualize the models loss 
#plt.plot(history.history['acc'])
#plt.plot(history.history['loss'])
#plt.title('model accuracy and loss')
#plt.ylabel('accuracy and loss')
#plt.xlabel('epoch')

print('shape of test data:',x_train.shape)
print('shape of train data:', x_test.shape)

pred= model.predict(x_test)
pred = [1 if y>=0 else 0 for y in pred]

print('original: {0}'.format(",".join(str(x) for x in y_test)) )
print('prediction: {0}'.format(",".join(str(x) for x in pred)) )